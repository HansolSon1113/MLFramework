{
 "cells": [
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-13T11:38:53.030510Z",
     "start_time": "2026-02-13T11:38:38.718316Z"
    }
   },
   "cell_type": "code",
   "source": [
    "// GPU Training Test for Housing Dataset\n",
    "\n",
    "import hs.ml.model.Model\n",
    "import hs.ml.model.nn.Dense\n",
    "import hs.ml.model.nn.activation.ReLU\n",
    "import hs.ml.autograd.Node\n",
    "import hs.ml.importer.CsvImporter\n",
    "import hs.ml.preprocessing.DataPreprocessor\n",
    "import hs.ml.preprocessing.policy.ReplaceToAvgPolicy\n",
    "import hs.ml.scaler.MinMaxScaler\n",
    "import hs.ml.data.DataPipeline\n",
    "import hs.ml.train.Trainer\n",
    "import hs.ml.loss.MeanSquaredError\n",
    "import hs.ml.metric.RootMeanSquaredError\n",
    "import hs.ml.train.optimizer.Adam\n",
    "import hs.ml.math.TensorFactory\n",
    "import hs.ml.math.metal.MetalConfig\n",
    "\n",
    "// Enable GPU acceleration\n",
    "TensorFactory.useGpu = true\n",
    "MetalConfig.enabled = true\n",
    "MetalConfig.minSizeForGPU = 100\n",
    "\n",
    "println(\"=== GPU Training Test ===\")\n",
    "println(\"GPU Enabled: ${TensorFactory.useGpu}\")\n",
    "println(\"Metal Available: ${MetalConfig.isAvailable()}\")\n",
    "println(\"Metal Backend: ${MetalConfig.getBackend()}\")\n",
    "println()\n",
    "\n",
    "// Define the neural network model\n",
    "class HousingModel(inputSize: Int) : Model() {\n",
    "    private val fc1 = Dense(inputSize, 32)\n",
    "    private val fc2 = Dense(32, 16)\n",
    "    private val output = Dense(16, 1)\n",
    "    private val relu = ReLU()\n",
    "\n",
    "    override fun forward(x: Node): Node {\n",
    "        var h = fc1.forward(x)\n",
    "        h = relu.forward(h)\n",
    "        h = fc2.forward(h)\n",
    "        h = relu.forward(h)\n",
    "        return output.forward(h)\n",
    "    }\n",
    "\n",
    "    override fun params(): List<Node> {\n",
    "        return fc1.params() + fc2.params() + output.params()\n",
    "    }\n",
    "}\n",
    "\n",
    "// Load and preprocess data\n",
    "println(\"Loading housing dataset...\")\n",
    "val importer = CsvImporter(\"data/housing.csv\")\n",
    "val preprocessor = DataPreprocessor(\n",
    "    missingPolicy = ReplaceToAvgPolicy(),\n",
    "    scaler = MinMaxScaler()\n",
    ")\n",
    "val pipeline = DataPipeline(importer, preprocessor)\n",
    "val data = pipeline.run()\n",
    "\n",
    "println(\"Data shape: ${data.inputs.row} x ${data.inputs.col}\")\n",
    "println(\"Labels shape: ${data.labels.row} x ${data.labels.col}\")\n",
    "println()\n",
    "\n",
    "// Split data into train and test sets (80/20 split)\n",
    "val splitIndex = (data.inputs.row * 0.8).toInt()\n",
    "val trainInputs = TensorFactory.create(splitIndex, data.inputs.col) { i, j -> data.inputs[i, j] }\n",
    "val trainLabels = TensorFactory.create(splitIndex, 1) { i, _ -> data.labels[i, 0] }\n",
    "val testInputs = TensorFactory.create(data.inputs.row - splitIndex, data.inputs.col) { i, j -> \n",
    "    data.inputs[i + splitIndex, j] \n",
    "}\n",
    "val testLabels = TensorFactory.create(data.inputs.row - splitIndex, 1) { i, _ -> \n",
    "    data.labels[i + splitIndex, 0] \n",
    "}\n",
    "\n",
    "val trainBatch = hs.ml.data.DataBatch(trainInputs, trainLabels)\n",
    "val testBatch = hs.ml.data.DataBatch(testInputs, testLabels)\n",
    "\n",
    "println(\"Train set: ${trainBatch.inputs.row} samples\")\n",
    "println(\"Test set: ${testBatch.inputs.row} samples\")\n",
    "println()\n",
    "\n",
    "// Create and configure model\n",
    "val model = HousingModel(data.inputs.col)\n",
    "model.param.loss = MeanSquaredError()\n",
    "model.param.optimizer = Adam(lr = 0.001)\n",
    "model.param.metric = mutableListOf(RootMeanSquaredError())\n",
    "\n",
    "// Create trainer\n",
    "val trainer = Trainer(model)\n",
    "\n",
    "// Training callback to print progress\n",
    "val verbose: (Int, String) -> Unit = { epoch, msg ->\n",
    "    println(\"Epoch $epoch: $msg\")\n",
    "}\n",
    "\n",
    "println(\"Starting GPU training...\")\n",
    "val startTime = System.currentTimeMillis()\n",
    "\n",
    "trainer.train(\n",
    "    train = trainBatch,\n",
    "    test = testBatch,\n",
    "    epochs = 1000,\n",
    "    verbose = verbose,\n",
    "    evalEpoch = 100\n",
    ")\n",
    "\n",
    "val endTime = System.currentTimeMillis()\n",
    "val trainingTime = (endTime - startTime) / 1000.0\n",
    "\n",
    "println()\n",
    "println(\"=== Training Complete ===\")\n",
    "println(\"Total training time: ${trainingTime}s\")\n",
    "println(\"Final epoch: ${model.epoch}\")\n",
    "println(\"Model trained: ${model.isTrained}\")\n",
    "println()\n",
    "\n",
    "// Final evaluation\n",
    "println(\"=== Final Evaluation ===\")\n",
    "val finalMetrics = trainer.evaluate(testBatch)\n",
    "finalMetrics.forEach { (name, value) ->\n",
    "    println(\"$name: ${String.format(\"%.6f\", value)}\")\n",
    "}"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== GPU Training Test ===\n",
      "GPU Enabled: true\n",
      "Metal Available: false\n",
      "Metal Backend: null\n",
      "\n",
      "Loading housing dataset...\n",
      "DataPreprocessor: 전처리 시작...\n",
      "DataPreprocessor: 전처리 완료.\n",
      "Data shape: 20640 x 8\n",
      "Labels shape: 20640 x 1\n",
      "\n",
      "Train set: 16512 samples\n",
      "Test set: 4128 samples\n",
      "\n",
      "Starting GPU training...\n",
      "Epoch 1: Training started: Epoch 1 to 1000\n"
     ]
    }
   ],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": ""
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Kotlin",
   "language": "kotlin",
   "name": "kotlin"
  },
  "language_info": {
   "name": "kotlin",
   "version": "2.2.20-dev-4982",
   "mimetype": "text/x-kotlin",
   "file_extension": ".kt",
   "pygments_lexer": "kotlin",
   "codemirror_mode": "text/x-kotlin",
   "nbconvert_exporter": ""
  },
  "ktnbPluginMetadata": {
   "projectLibraries": false,
   "projectDependencies": [
    "oop-ml.main"
   ]
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
